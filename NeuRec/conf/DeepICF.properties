[hyperparameters]
pretrain_file=None

#Interval of evaluation
verbose=1

#adagrad,rmsprop,adam
learner=adam

#user: generate batches by user, fixed:batch_size: generate batches by batch size
batch_size=256

#Number of epochs.
epochs=300
#Size of each layer
layers=[64,32,16]

weight_size=16

embedding_size=16

#Index of coefficient of embedding vector
data_alpha=0

#Regularization for user and item embeddings.[1e-7,1e-7,0]
regs=[0.000001,0.000001,0.00001]
#L_2 regularization on each layer weights.
regw=[10,10]
#Index of coefficient of embedding vector
alpha=0

#Index of coefficient of sum of exp(A)
beta=0.5

#Number of negative instances to pair with a positive instance.
num_neg=4

learning_rate=0.001

#Activation for ReLU, sigmoid, tanh.
activation=Relu

#0 for deepICF_prod, 1 for deepicf_concat
algorithm=1

#Whether to perform batch norm (0 or 1)
batch_norm=1

#tnormal: truncated_normal_initializer, uniform: random_uniform_initializer,
#normal: random_normal_initializer, xavier_normal, xavier_uniform, 
#he_normal, he_uniform. Defualt: tnormal
embed_init_method=tnormal
weight_init_method=he_normal
bias_init_method=he_normal
stddev=0.01
