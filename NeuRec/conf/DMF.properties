[hyperparameters]
epochs=30
batch_size=256
reg_mf=0
layers=[200,100]
learning_rate=0.0001
loss_function=cross_entropy
learner=adam
num_negatives=4
#tnormal:truncated_normal_initializer, uniform: random_uniform_initializer,
#normal: random_normal_initializer, xavier_normal, xavier_uniform, 
#he_normal, he_uniform. Defualt: tnormal
init_method=normal
stddev=0.01
verbose=1