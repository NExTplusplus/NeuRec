[hyperparameters]
epochs=300
batch_size=256
embedding_size=100
learning_rate=0.001
num_layers=2
activation=sigmoid
loss_function=BPR
learner=adam
reg=0.001
dropout=0.0
#tnormal: truncated_normal_initializer, uniform: random_uniform_initializer,
#normal: random_normal_initializer, xavier_normal, xavier_uniform, 
#he_normal, he_uniform. Defualt: tnormal
embed_init_method=xavier_normal
weight_init_method=xavier_normal
stddev=0.01
verbose=1