[hyperparameters]
epochs=100
batch_size=256
layers=[64,32,16]
reg_mlp=0.0
learning_rate=0.001
learner=adam
is_pairwise=False
num_neg=4
#pairwise:BPR,hinge,square
#pointwise:cross_entropy,square
loss_function=cross_entropy
verbose=1
#tnormal:truncated_normal_initializer, uniform: random_uniform_initializer,
#normal: random_normal_initializer, xavier_normal, xavier_uniform, 
#he_normal, he_uniform. Defualt: tnormal
init_method=normal
stddev=0.01